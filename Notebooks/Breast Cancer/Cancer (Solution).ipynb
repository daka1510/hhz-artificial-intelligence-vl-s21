{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Wisconsin Data Set\n",
    "\n",
    "Create a predictive model that classifies benign vs. malignant tumors. \n",
    "See https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/data for data understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the file\n",
    "my_file = project.get_file(\"data.csv\")\n",
    "\n",
    "# Read the CSV data file from the object storage into a pandas DataFrame\n",
    "my_file.seek(0)\n",
    "original_data = pd.read_csv(my_file)\n",
    "\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.describe(include='all') # descriptive statistics for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.isnull().sum() # check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data[original_data.duplicated(keep=False)] # check for duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values and no duplicates, so you don't have to take actions here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data[['radius_mean', 'diagnosis']].groupby(['diagnosis'], as_index=False).mean().sort_values(by='diagnosis', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect more feature, e.g. texture, perimeter,... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "original_data[['texture_mean', 'diagnosis']].groupby(['diagnosis'], as_index=False).mean().sort_values(by='diagnosis', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "original_data[['perimeter_mean', 'diagnosis']].groupby(['diagnosis'], as_index=False).mean().sort_values(by='diagnosis', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important step during feature selection is removing features that strongly correlate with each other. You keep only one feature as \"representer\" of the information and remove redundant features. There are more advanced methods to do this but, for now, just look at the correlation map and decide which features to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize = (18,18))\n",
    "sns.heatmap(original_data.corr(),annot= True,linewidths=0.5,fmt = \".1f\",ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Correlation Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reduced_features = original_data[['<your feature 1>', '<your feature 2>','...']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "data_reduced_features = original_data[['diagnosis', 'radius_mean', \n",
    "                                       'smoothness_mean', 'compactness_mean',\n",
    "                                       'symmetry_mean','fractal_dimension_mean',\n",
    "                                       'radius_se', 'texture_se','smoothness_se',\n",
    "                                       'compactness_se', 'symmetry_se',\n",
    "                                       'fractal_dimension_se','symmetry_worst'\n",
    "                                       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reduced_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, have a look at the correlation map and remove more features if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize = (18,18))\n",
    "sns.heatmap(data_reduced_features.corr(),annot= True,linewidths=0.5,fmt = \".1f\",ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Correlation Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set X and y (predictors and target) according to your dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_reduced_features['<your target column>']\n",
    "predictors = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "target = data_reduced_features['diagnosis']\n",
    "predictors = data_reduced_features.drop(['diagnosis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=123) # 80-20 split into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data balancing\n",
    "y_train.value_counts()\n",
    "\n",
    "# There is no severe skew in the class distribution. No resampling needed.\n",
    "# If you want to learn more about resampling, also check https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use StandardScaler to scale your predictors (fit on training set and transform training and test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = # your code \n",
    "# your code\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models and evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a decision tree classifier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "# your code\n",
    "\n",
    "print('train performance')\n",
    "print(classification_report(y_train, tree.predict(X_train))) \n",
    "print('test performance')\n",
    "print(classification_report(y_test, tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "print('train performance')\n",
    "print(classification_report(y_train, tree.predict(X_train))) \n",
    "print('test performance')\n",
    "print(classification_report(y_test, tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you evaluate this result (hints: overfitting vs. underfitting, which metric might be important for the use case and why)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musterlösung\n",
    "\n",
    "overfitting, seen in 100% training performance\n",
    "\n",
    "(Value might be different in your case depending on the predictors you have chosen! Still, there will probably be a (significant) difference between training and test performance)\n",
    "\n",
    "recall of malign should be the most important metric: \n",
    "you would rather treat a person with a benign tumor than missing a malignant one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test, tree.predict(X_test))\n",
    "df_cm = pd.DataFrame(conf_mat, index=['B','M'], columns=['B', 'M'],)\n",
    "fig = plt.figure(figsize=[10,7])\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "# your code\n",
    "print('train performance')\n",
    "print(classification_report(y_train, logreg.predict(X_train)))\n",
    "print('test performance')\n",
    "print(classification_report(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Musterlösung\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print('train performance')\n",
    "print(classification_report(y_train, logreg.predict(X_train)))\n",
    "print('test performance')\n",
    "print(classification_report(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you evaluate this result? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musterlösung\n",
    "overfitting seems to be no issue here\n",
    "\n",
    "recall of malignant better than for decision tree but could still be optimized (currently around 90% for test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test, logreg.predict(X_test))\n",
    "df_cm = pd.DataFrame(conf_mat, index=['B','M'], columns=['B', 'M'],)\n",
    "fig = plt.figure(figsize=[10,7])\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to try out more classifiers (don't forget to import required packages!), change classifier parameters, modify train and test split, select other predictors,...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the logistic regression and/or decision tree model via the _Watson Machine Learning_ (WML) service on IBM Cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Python client library (documentation available at http://ibm-wml-api-pyclient.mybluemix.net/)\n",
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your IBM Cloud API key \n",
    "api_key = \"\"\n",
    "\n",
    "# set the URL of your WML instance \n",
    "# depending on the region you chose during instance creation it will take one of the below values:\n",
    "# - Frankfurt: https://eu-de.ml.cloud.ibm.com\n",
    "# - Dallas: https://us-south.ml.cloud.ibm.com\n",
    "# - London: https://eu-gb.ml.cloud.ibm.com\n",
    "# - Tokyo: https://jp-tok.ml.cloud.ibm.com\n",
    "wml_url = \"https://eu-de.ml.cloud.ibm.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the API client\n",
    "wml_client = APIClient({\n",
    "   \"url\": wml_url,\n",
    "   \"apikey\": api_key\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all existing deployment spaces\n",
    "wml_client.spaces.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the id of the deployment space you want to use as default\n",
    "wml_client.set.default_space(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup required properties to store the model\n",
    "sofware_spec_uid = wml_client.software_specifications.get_id_by_name(\"default_py3.7\")\n",
    "metadata = {\n",
    "            wml_client.repository.ModelMetaNames.NAME: 'Cancer Model',\n",
    "            wml_client.repository.ModelMetaNames.TYPE: 'scikit-learn_0.23',\n",
    "            wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid\n",
    "}\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign your favorite model to the deployment_classifier variable\n",
    "deployment_classifier = logreg\n",
    "deployment_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the scikit-learn model in WML\n",
    "model = wml_client.repository.store_model(deployment_classifier, meta_props=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review available models in your WML instance\n",
    "wml_client.repository.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the id of the model you deployed\n",
    "published_model_uid = wml_client.repository.get_model_uid(model)\n",
    "published_model_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup required properties to deploy the model\n",
    "metadata = {\n",
    "    wml_client.deployments.ConfigurationMetaNames.NAME: \"Deployment of Cancer model\",\n",
    "    wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the model as a web service (an API endpoint is generated for your deployment so your tools and apps can use a REST API to send data to your deployed model for analysis)\n",
    "created_deployment = wml_client.deployments.create(published_model_uid, name=\"Cancer Deployment\", meta_props=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the REST API endpoint for evaluation\n",
    "scoring_endpoint = wml_client.deployments.get_scoring_href(created_deployment)\n",
    "scoring_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the stored deployment to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review original data\n",
    "original_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review predictors\n",
    "predictors.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests module\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the request payload as per the API documentation\n",
    "scoring_values = predictors.iloc[0:2].to_numpy().tolist()\n",
    "payload_scoring = {\"input_data\": [{\"values\": scoring_values}]}\n",
    "payload_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a token to make an authenticated request\n",
    "token_response = requests.post('https://iam.eu-de.bluemix.net/identity/token', data={\"apikey\": api_key, \"grant_type\": 'urn:ibm:params:oauth:grant-type:apikey'})\n",
    "mltoken = token_response.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the scoring request\n",
    "header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\n",
    "response_scoring = requests.post(f'{scoring_endpoint}?version=2020-10-10', json=payload_scoring, headers={'Authorization': 'Bearer ' + mltoken})\n",
    "response_scoring.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the results match your expectation? Were they classified correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the local model to make the same prediction in your notebook and compare the results\n",
    "deployment_classifier.predict(predictors.iloc[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the newly created artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list deployments\n",
    "wml_client.deployments.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete deployments you just created \n",
    "wml_client.deployments.delete(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list models\n",
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete models you just created\n",
    "wml_client.repository.delete(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
